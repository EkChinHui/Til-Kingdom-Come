Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Is Training
50000,1.4245417,4.3706765,260.80104712041884,-102.09505314529018,-102.09505314529018,59.554985,0.027281791,0.0002846001,0.1948667,0.0047438485,1.0
100000,1.4270122,-0.9729268,305.15337423312883,-137.11114271501168,-137.11114271501168,53.30578,0.023035575,0.00025686325,0.1856211,0.004282492,1.0
150000,1.4266448,-5.4740424,286.43529411764706,-119.71710820837299,-119.71710820837299,38.251274,0.026155159,0.00022601527,0.17533842,0.0037693859,1.0
200000,1.4274907,-8.071016,366.48201438848923,-146.40000931176914,-146.40000931176914,31.30239,0.024053173,0.00019519372,0.16506454,0.003256722,1.0
250000,1.4293936,-8.983397,412.0508474576271,-162.69042038272744,-162.69042038272744,29.850037,0.025064752,0.00016434654,0.15478216,0.0027436302,1.0
300000,1.4308246,-11.353924,357.2027972027972,-128.83817518729933,-128.83817518729933,23.733805,0.023135267,0.0001334949,0.1444983,0.002230464,1.0
350000,1.4303672,-11.516524,364.4963503649635,-119.74159957005737,-119.74159957005737,20.210245,0.024069387,0.00010268384,0.13422793,0.0017179729,1.0
400000,1.4304402,-12.616445,385.2755905511811,-142.5842103461857,-142.5842103461857,24.272024,0.022289831,7.498898e-05,0.12499629,0.0012573155,1.0
450000,1.4298158,-11.958027,467.1926605504587,-156.60908303762105,-156.60908303762105,20.899652,0.026093459,4.7256202e-05,0.11575204,0.0007960267,1.0
500000,1.4297234,-11.863357,520.9239130434783,-179.71072082821837,-179.71072082821837,21.261776,0.02252997,1.6449338e-05,0.10548308,0.00028360577,1.0
